#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Thu Oct 17 17:25:20 2019
@author: marleezinsser
"""

from Bio import Entrez
import requests
import xml.etree.ElementTree as ET
from lxml import etree
import csv
import json
import pandas as pd
import urllib.parse
import sys




# Searches PUBMED for PMIDs that can be fed back into PTC to retrieve annotated
#articles
def search(query, search_place):
    Entrez.email = "marleejzinsser@gmail.com"
    m_search = Entrez.esearch(db="pubmed", 
                            retstart = search_place,
                            sort="relevance", 
                            retmax=100,
                            mindate = 2010,
                            maxdate = 2018,
                            term=query)
    results = Entrez.read(m_search)
    return results


def get_annotations(a,b,query,aggregate, m_format):  
    
    columns = ['PMID', 'Delete1', 'Delete2', 'Disease','Delete3', 'MESH']
    main_df = pd.DataFrame(columns = columns)

    #Use my search function to search for 'heart failure' multiple times through for loop:
    for x in range (a,b):
        if a == 0:
            result_num = 0
        else:
            result_num = x*100
        print ("start search at result number: ",result_num)
        results = search(query, result_num)
        
        #Store the PMIDs
    
        id_list = results["IdList"]
        print ("searching for: ")
        print (len(id_list)," ids")
    
        #Put IDs in comma-separated list, suitable format for a get call to 
        #PubTator Central API
        ids = ','.join(id_list)
        print ("searching for id(s): ", ids)
        
        
        #Construct a url from the list of IDs plus the base https components and
        # format, here format is "pubtator"
        oldurl = "https://www.ncbi.nlm.nih.gov/CBBresearch/Lu/Demo/RESTful/tmTool.cgi/Disease/" + ids + "/pubtator/"
        
        url = "https://www.ncbi.nlm.nih.gov/research/pubtator-api/publications/export/pubtator?pmids=" + ids + "&concepts=disease"

        #url = "https://www.ncbi.nlm.nih.gov/research/pubtator-api/publications/export/pubtator?pmids=28483577&concepts=disease"

        #Get allows me to speciy Disease as type, enter 100-1000 PMIDS
        #response = requests.post(url, headers = headers)
        response = requests.get(url)
        
        #Print the responses in (currently) Pubtator Format
        #print (response.text.encode("utf-8"))
        
        #convert the Response to a string in Pubtator Format (henceforth ptf)
        from io import StringIO
        ptf_str = response.text
        
        if (m_format == 'XML' or m_format == 'json'):
            return ptf_str
        else:
            ptf_str = StringIO(ptf_str)
    
            #Read in csv file and convert to df
            columns = ['PMID', 'Delete1', 'Delete2', 'Disease','Delete3', 'MESH']
            df = pd.DataFrame(columns = columns)
            #df = pd.read_csv('output.csv', delimiter = '\t',names = columns)
            df = pd.read_csv(ptf_str, delimiter = '\t', names = columns)
    
        
            main_df = main_df.append(df)
        
    #del main_df ['Delete1']
   # del main_df ['Delete2']
    #del main_df ['Delete3']
    
    if (aggregate == True):
        aggregate_results(main_df)
    
    print (main_df)
    return main_df



def aggregate_results(main_df):
    main_df['Number_of_Times_Annotated'] = 1 

    aggregation_functions = {'Number_of_Times_Annotated': 'sum', 'PMID':'first', 'MESH':'first', 'Disease':'first'}
    agg_df= main_df.groupby(['PMID','MESH', 'Disease']).aggregate(aggregation_functions)
    #agg_df= main_df.groupby(['PMID','MESH', 'Disease']).aggregate(aggregation_functions)
   # agg_df= main_df.groupby(['MESH', 'Disease', 'PMID']).aggregate(aggregation_functions)

    agg_df = agg_df.reset_index(drop=True)

    cols = agg_df.columns.tolist()
    cols = cols [1:] + cols [:1]
    agg_df=agg_df[cols]
    
    agg_df['Disease'] = agg_df['Disease'].str.lower()
    
    agg_df = aggregate_results2(agg_df)
    return agg_df



def aggregate_results2(main_df):
   # main_df['Number_of_Times_Annotated'] = 1 

    aggregation_functions = {'Number_of_Times_Annotated': 'sum', 'PMID':'first', 'MESH':'first', 'Disease':'first'}
    agg_df= main_df.groupby(['PMID','MESH', 'Disease']).aggregate(aggregation_functions)
    #agg_df= main_df.groupby(['PMID','MESH', 'Disease']).aggregate(aggregation_functions)
   # agg_df= main_df.groupby(['MESH', 'Disease', 'PMID']).aggregate(aggregation_functions)

    agg_df = agg_df.reset_index(drop=True)

    cols = agg_df.columns.tolist()
    cols = cols [1:] + cols [:1]
    agg_df=agg_df[cols]
    
    agg_df['Disease'] = agg_df['Disease'].str.lower()
    return agg_df
